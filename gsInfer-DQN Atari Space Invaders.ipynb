{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = retro.make(game='SpaceInvaders-Atari2600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our frame is:  Box(210, 160, 3)\n",
      "The action size is:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The size of our frame is: \", env.observation_space)\n",
    "print(\"The action size is: \", env.action_space.n)\n",
    "# Here we create an hot encoded version of our actions\n",
    "# possible_actions = [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]...]\n",
    "possible_actions = np.array(np.identity(env.action_space.n, dtype=int).tolist())\n",
    "possible_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess frame\n",
    "# Take a fraem\n",
    "# Garyscale it\n",
    "# Resize it\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    gray = rgb2gray(frame)\n",
    "    # Crop the screen (remove the part below the player)\n",
    "    # Up: Down, Left: right\n",
    "    cropped_frame = gray[8:-12, 4:-12]\n",
    "    \n",
    "    normalized_frame = cropped_frame/255.0\n",
    "    \n",
    "    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n",
    "    \n",
    "    return preprocessed_frame # 110 X 84 * 1 frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack size:  4\n",
      "frame shape:  (110, 84)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Stack frames\n",
    "\n",
    "Stacking frames give have a sense of motion to our NN\n",
    "But, we don't stack each frames, we skip 4 frames at each timestep. This means that only every fourth frame is considered. \n",
    "And then, we use this frame to form the stack_frame\n",
    "The frame skipping method is already implemented in the library:\n",
    "* First we preprocess frame\n",
    "* Then we append the frame to the deque that automatically removes the oldest frame\n",
    "* Finally we build the stacked state\n",
    "\n",
    "This is how work stack:\n",
    "* For the first frame, we feed 4 frames\n",
    "* At each timestep, we add the new frame to deque and then we stack them to form a new stacked frame\n",
    "* And so on\n",
    "* If we're done, we create a new stack with 4 new frames because we are in a new episode\n",
    "\"\"\"\"\"\n",
    "\n",
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "print(\"stack size: \", len(stacked_frames))\n",
    "#print(stacked_frames[0])\n",
    "print(\"frame shape: \", stacked_frames[0].shape)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # Preprocess frame\n",
    "    frame = preprocess_frame(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "        # Build the stacked state (first dimenstion specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "        \n",
    "    return stacked_state, stacked_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### MODEL HYPERPARAMETERS\n",
    "state_size = [110, 84, 4] # Our input is a stack of 4 frames 110 * 84 * 4 (width, heifht, channel)\n",
    "action_size = env.action_space.n # 8 possible actions\n",
    "learning_rate = 0.00025\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DDDQNNet \n",
    "\n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNetwork = DDDQNNet.DDDQNNetwork(state_size, action_size, learning_rate, name=\"DQNetwork\")\n",
    "tf = DQNetwork.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset the graph\n",
    "# tf.reset_default_graph()\n",
    "# # Instantiate the DQNetwork\n",
    "# DQNetwork = DQNetwork(state_size, action_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = io.BytesIO()\n",
    "    ima = PIL.Image.fromarray(a).save(f, fmt)\n",
    "    return f.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG_PRINT = True\n",
    "DEBUG_PRINT = False\n",
    "def print_var(var_name, var_value, debug=False):\n",
    "    \"\"\"\n",
    "    test = 123\n",
    "    print_var(\"test\", test)    \n",
    "    \"\"\"\n",
    "    if DEBUG_PRINT:\n",
    "        print(var_name, \": \", var_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAAD5UlEQVR4nO3dMa7dRBQAUH+UNVCRFFRIiCZV9kCDQkWThTxRoreQ9NCxh1RpUCQqCsJCKIyezAPH9v++4+s75xTR/9GNn+fduR7bM3aGAQAAAADO4GH6y8ufXi7+g/c/vg/bmXvR+/P2+mox5s3l3aO3v1XE/jwsh8zbmoBsHWirrQnI0IFmK3guMUdVcMTnThMwl5ijKniv/dmtgtd0iGwdaKutCcjQgU5TwXP2GoNV8P9Qwfv+fYTUFTxnr/3JkIDo/VHBG5Sq4DlVx+A5roMXuA5eHw8AAAAAAAAAAAAUdL0+F1/cXZsXv4Le4iu4NXL8Yf131El8Bdfr87tmi2/pSU82fNpd8y6Xj+Lb+yx062Mjxz/XdOfe4huITfDWoai3+AZiE0xl2S5LssW3EVXB2b7NbPEAAABAgMDZpOHf1/trZld6i28g8F50tptH2eLbaDFdOKzuzr3FNxB1iJ7rv3Mt7y3+9O5mRhcnSnuLb+ZZ6NYvl49jI9cf4rqKP7dbL960JLGf+Das6ChOgouLHYOH7aNRb/EAAAAAZHGdPPEuvj1Ldg6LP7fp3NmaGbTe4puxJuvI+AZMF/Io2dZAZYsv4q7B4kvJdtaaLb6CbBWTLR4AAADYlXd0HBnfgAn/w+LbiH2d8PQV98Mn29xbfDPt/lOOYemo1Vt8G4GH6LvmLba2t/gKss3eZIs/t2wnNdni2whfk3VNtg45W/y5ZTskZosHAAAAYD0rOo6Mb8CKjsPi2whf0THtyGtWRHQS34wn/IuLfSH41i7cW/zpXTe+cqa3+Aa80v/g+GjG4OIkuLioQ/R0BFo5enUVDwAAAPQg28NhZ3/4LHbJzib//V7O9cT+1vg2styLvq2IGH8df1izguKk8c1kSfAo2+OdHh/dU7ZFcRbdwUbZJvVMGu4vWw7OnmOHaJrLdq7rXBoAAAAAAACAdBItfI/z6/dfDcPw7c+/h25/FPcpj2PJTnHHJ3ja/Rtsf/ePi97+Ex2fYEIdn+DboNWglLOVVwPHJ5hQxyf4VlXZzj9rOD7BhEqU4D7HyGiJEkyEgxM8luz0TtO+Rdz4IrvNh26igosLf+P7Sql6fSUquLgeE9zV0aLHBHclxRg8vYcVUV5n3/5TqGAAAAAAIIEunk2a8/b6ajHmzeVdgz2J4150cSlmkzKYVuqayj4LFVycBBcnwcVJcHESXJyz6H9UOnOeUsHFLdzJ+u6Hz9vsB0FmE7xjav/8+othGF58+GuvDZ7X62++HIbhl9/+aPaJz9Robcbg4iS4OAku7sEYXJsKLk6Ci5Pg4iS4OAkuToKLk+DiJLi4vwErGGnJnRqTJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 450
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 5.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    total_test_rewards = []\n",
    "    \n",
    "    # Load the model\n",
    "#    saver.restore(sess, \"./models/model.ckpt\")\n",
    "    saver.restore(sess, \"./play_model/model.ckpt\")\n",
    "    \n",
    "    for episode in range(1):\n",
    "        total_rewards = 0\n",
    "        \n",
    "        state = env.reset()\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "        \n",
    "        imagehandle = display.display(display.Image(data=showarray(env.render(mode='rgb_array')), width=450), display_id='gymscr')\n",
    "        \n",
    "        play_step = 0\n",
    "        while True:\n",
    "#        while play_step < 10:      \n",
    "            ## EPSILON GREEDY STRATEGY\n",
    "            # Choose action a from state s using epsilon greedy\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = np.random.rand()\n",
    "            explore_probability = 0.01\n",
    "            \n",
    "            if (explore_probability > exp_exp_tradeoff):\n",
    "                # Make a random action (exploration)\n",
    "                action = random.choice(possible_actions)\n",
    "            else:\n",
    "                # Get action from Q-network (Exploitation)\n",
    "                # Estimate the Qs values state\n",
    "                \n",
    "                # Reshape the state\n",
    "                state = state.reshape((1, *state_size))\n",
    "                Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state})\n",
    "                # Take the biggerest Q values (= the best action)\n",
    "                choice = np.argmax(Qs)\n",
    "                action = possible_actions[choice]\n",
    "    \n",
    "            \n",
    "            \n",
    "            #Perform the action and get the next_state, reward, and done information\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "#            print_var(\"next_state\", next_state)                            \n",
    "            print_var(\"reward\", reward)                            \n",
    "            print_var(\"done\", done)                                        \n",
    "#            env.render()\n",
    "            #show_state(env, step = play_step)\n",
    "            display.update_display(display.Image(data=showarray(env.render(mode='rgb_array')), width=450), display_id='gymscr')\n",
    "            \n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                print (\"Score\", total_rewards)\n",
    "                total_test_rewards.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "                \n",
    "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "            state = next_state\n",
    "            play_step += 1\n",
    "            \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
